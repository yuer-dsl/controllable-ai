# Controllable AI Governance Position Statement

**Document Type:** Governance Position Statement  
**Status:** Frozen  
**Scope:** Structural / Non-Technical  
**Authority Level:** Normative (Position Only)

---

## 1. Purpose of This Document

This document defines the **structural position of Controllable AI**
within the broader field of **AI Governance**.

It does NOT:

- Propose ethical values
- Define policy frameworks
- Recommend regulatory actions
- Replace legal or institutional governance

Its sole purpose is to establish **where Controllable AI exists,
and where it explicitly does not.**

---

## 2. Core Position

> **Controllable AI is not AI Governance itself.**  
> **Controllable AI is the execution-time legality layer required by any effective AI Governance system.**

AI Governance may define:
- What should be done
- Who is responsible
- How risks are categorized

**Controllable AI decides only one thing:**

> **Whether an AI-driven action is permitted to occur at execution time.**

---

## 3. Structural Layering

AI Governance operates across multiple layers, including but not limited to:

- Ethics and value principles
- Organizational responsibility
- Risk classification and compliance
- Oversight and accountability processes

These layers primarily answer:
- *Should this be done?*
- *Who authorizes it?*
- *Who bears responsibility?*

**Controllable AI answers none of the above.**

It answers only:

> *Is this specific AI-driven action allowed to execute under the current responsibility and constraint structure?*

---

## 4. Non-Substitutability

Any AI Governance framework that lacks Controllable AI:

- Cannot enforce execution-time veto
- Cannot guarantee Fail-Closed behavior
- Cannot prevent responsibility laundering
- Cannot produce replayable legality evidence

In such cases, governance exists only:
- In documentation
- In policy
- In intent

**But not in reality.**

---

## 5. Explicit Non-Coverage

Controllable AI does NOT cover and must NOT be interpreted as covering:

- Ethical judgment
- Social impact assessment
- Policy formation
- Risk prioritization
- AI capability optimization
- Performance benchmarking

Controllable AI **does not evaluate intelligence**.  
It evaluates **permission**.

---

## 6. Authority Boundary

Controllable AI:

- Does not issue moral authority
- Does not replace human decision-makers
- Does not act as a regulator
- Does not define acceptable outcomes

It is a **non-AI, non-autonomous legality gate**.

---

## 7. One-Sentence Summary

> **AI Governance defines direction.  
> Controllable AI defines permission.**

Without Controllable AI,
AI Governance cannot effectively bind AI behavior in the real world.

---

## 8. Freeze Declaration

This position is frozen to prevent future reinterpretation.

Any future work referencing Controllable AI MUST preserve its role as:

> **An execution-time, non-autonomous, non-negotiable legality enforcement layer.**

---
