# IMPLEMENTATIONS

## Reference Implementations & Non-Authoritative Systems

---

## 1. Document Purpose

This document enumerates **reference implementations**
that claim compatibility with the **Controllable AI Specification**.

Its sole purpose is to:

- Prevent implementation-level authority escalation
- Prevent redefinition of Controllable AI through code
- Maintain strict separation between **specification** and **execution**

This document is **informative**, not normative.

---

## 2. Core Principle

> **No implementation defines Controllable AI.**  
> **Implementations may only demonstrate compatibility.**

Compliance flows in one direction only:


Specification → Constraints → Implementation


Reverse interpretation is invalid by definition.

---

## 3. Definition: Reference Implementation

A **Reference Implementation** is any system that:

- Publicly claims alignment with the Controllable AI Specification
- Demonstrates how constraints may be enforced in practice
- Does NOT assert governance authority
- Does NOT redefine terminology
- Does NOT weaken or reinterpret veto conditions

Reference implementations exist to **illustrate**, not to certify.

---

## 4. Non-Exhaustive List of Known Implementations

The following systems are acknowledged as **non-authoritative reference implementations**.

Their inclusion here does NOT imply endorsement, certification, or exclusivity.

---

### 4.1 EDCA OS (Expression-Driven Cognitive Architecture OS)

**Repository:**  
https://github.com/yuer-dsl/EDCA-OS  

**Role:**  
A controllable AI operating architecture designed to enforce:

- Explicit execution boundaries
- Structured decision pathways
- Human-mediated final authority

**Status:**  
Reference implementation only.  
Not a governance layer.  
Not a specification authority.

---

### 4.2 LSR Runtime

**Role:**  
A runtime-level execution control mechanism intended to:

- Enforce execution-time veto conditions
- Provide replayable decision traces
- Prevent implicit autonomous execution

**Status:**  
Optional execution runtime.  
Replaceable.  
Non-authoritative.

---

### 4.3 Yuer DSL

**Role:**  
A domain-specific language designed to:

- Explicitly encode constraints
- Remove ambiguity in AI execution contexts
- Prevent semantic drift between intent and action

**Status:**  
One possible constraint expression mechanism.  
Not required for compliance.

---

### 4.4 MAOK (Machine-Assisted Oversight Kernel)

**Repository:**  
https://github.com/yuer-dsl/maok  

**Role:**  
A structural enforcement and audit mechanism
focused on legality, veto, and replayability.

**Status:**  
Demonstrative enforcement kernel.  
Does not define Controllable AI.

---

### 4.5 Controllable AI Casebook

**Repository:**  
https://github.com/yuer-dsl/controllable-ai-casebook  

**Role:**  
A collection of applied scenarios illustrating:

- Execution-time veto enforcement
- Fail-Closed behavior
- Responsibility preservation

**Status:**  
Illustrative examples only.  
Not normative.

---

## 5. Non-Exclusivity Statement

This list is **explicitly non-exclusive**.

Any system may claim compatibility with Controllable AI **if and only if**:

- It complies with the normative specification
- It does not alter or reinterpret constraints
- It does not assert authority over governance definitions

Compatibility claims are falsifiable and subject to audit.

---

## 6. Prohibited Claims

Implementations MUST NOT claim:

- To be “the official Controllable AI system”
- To define or revise Controllable AI terminology
- To override specification requirements
- To replace human responsibility
- To act as a governance authority

Any such claim invalidates compatibility.

---

## 7. Interpretation Rule

In any conflict between:

- Specification and implementation
- Position statement and implementation
- Governance document and implementation

**The implementation is wrong by default.**

---

## 8. Final Statement

Implementations may evolve, fork, or disappear.

The Controllable AI Specification does not.

This document exists to ensure that
**execution remains subordinate to governance,
and governance remains subordinate to humans.**

---

